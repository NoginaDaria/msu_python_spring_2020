{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys\n",
    "from multiprocessing import Pool, Manager, Value, Lock\n",
    "from requests.exceptions import ConnectionError\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_id = list(map(str.strip, open('authors.txt', 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = 'https://www.respublica.ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(func):\n",
    "    @functools.wraps(func)\n",
    "    def decorated_func(*args, **kwargs):\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            result = None\n",
    "        with lock:\n",
    "            global counter\n",
    "            counter.value += 1\n",
    "            if counter.value % 50 == 0:\n",
    "                print(f\"{counter.value} -> \", end='', flush=True)\n",
    "        return result\n",
    "    return decorated_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrapper\n",
    "def get_page(url, n_attempts=5, t_sleep=1, **kwargs):\n",
    "    for _ in range(n_attempts):\n",
    "        page = requests.get(url, **kwargs)\n",
    "        if page.status_code >= 400:\n",
    "            time.sleep(t_sleep)\n",
    "        else:\n",
    "            return page.text\n",
    "    print(f'{n_attempts} attempts failed for url {url}', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_url(author_id):\n",
    "    begin = True\n",
    "    while True:\n",
    "        if begin:\n",
    "            page = get_page(site_name + f'/authors/{author_id}')\n",
    "            begin=False\n",
    "        else:\n",
    "            page = get_page(site_name + next_page)\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        if soup.find_all('a', class_=\"rd-listing-product-item__link\"):\n",
    "            books.append([i['href'] for i in soup.find_all('a', class_=\"rd-listing-product-item__link\")])\n",
    "        \n",
    "        next_page_region = soup.find('a', class_='pagination-next')\n",
    "        if next_page_region:\n",
    "            next_page = next_page_region['href']\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 -> 100 -> "
     ]
    }
   ],
   "source": [
    "lock = Lock()\n",
    "books = Manager().list()\n",
    "counter = Value('i', 0)\n",
    "with Pool(processes=len(authors_id)) as pool:\n",
    "    pool.map(get_books_url, authors_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = list(chain.from_iterable(books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(url):\n",
    "    book_dict = {}\n",
    "    \n",
    "    page = get_page(site_name + url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    book_dict['URL'] = site_name + url\n",
    "    \n",
    "    category_tmp = soup.find('div', class_='rd-page-product__breadcrumbs')\n",
    "    if category_tmp:\n",
    "        categories = category_tmp.find_all('span', class_=\"rd-page-breadcrumbs-item\")\n",
    "        if categories:\n",
    "            category_list = [i.text for i in categories]\n",
    "            category = '; '.join([i.strip(' ') for i in category_list])\n",
    "            book_dict['Категория'] = category\n",
    "    \n",
    "    name_tmp = soup.find('h1', class_=\"rd-page-product__title\")\n",
    "    if name_tmp:\n",
    "        name = name_tmp.text\n",
    "        book_dict['Название'] = name\n",
    "\n",
    "    author_tmp = soup.find_all('a', itemprop='brand')\n",
    "    if author_tmp:\n",
    "        author = '; '.join([i.text for i in author_tmp])\n",
    "        book_dict['Автор'] = author\n",
    "    \n",
    "    ID_tmp = soup.find('span', itemprop='sku')\n",
    "    if ID_tmp:\n",
    "        ID = ID_tmp.text\n",
    "        book_dict['ID'] = ID\n",
    "    \n",
    "    preview_tmp = soup.find('a', class_='download-pdf')\n",
    "    if preview_tmp:\n",
    "        preview_tmp1 = preview_tmp['href']\n",
    "        if preview_tmp1:\n",
    "            preview = site_name + preview_tmp1\n",
    "            book_dict['Превью'] = preview\n",
    "    \n",
    "    img_tmp1 = soup.find('div', class_='rd-page-product__photo')\n",
    "    if img_tmp1:\n",
    "        img_tmp2 = img_tmp1.img['src']\n",
    "        if img_tmp2:\n",
    "            image = site_name + img_tmp2\n",
    "            book_dict['Изображение'] = image\n",
    "    \n",
    "    price_tmp1 = soup.find('div', class_='rd-page-product__price')\n",
    "    if price_tmp1:\n",
    "        price_tmp2 = price_tmp1.span\n",
    "        if price_tmp2:\n",
    "            price = price_tmp2.text\n",
    "            price = \"\".join(price.split())\n",
    "            book_dict['Цена'] = int(price)\n",
    "    \n",
    "    old_price = soup.find('div', class_='rd-page-product__price-old')\n",
    "    if old_price:\n",
    "        old_price = old_price.span.text.split()[0]\n",
    "        old_price = \"\".join(old_price.split())\n",
    "        book_dict['Цена (старая)'] = int(old_price)\n",
    "    \n",
    "    ratings_tmp = soup.find('span', itemprop='aggregateRating')\n",
    "    if ratings_tmp:\n",
    "        score_tmp = ratings_tmp.find('meta', itemprop=\"ratingValue\")\n",
    "        if score_tmp:\n",
    "            score = score_tmp['content']\n",
    "            book_dict['Оценка'] = score\n",
    "        num_scores_tmp = ratings_tmp.find('meta', itemprop=\"ratingCount\")\n",
    "        if num_scores_tmp:\n",
    "            num_scores = num_scores_tmp['content']\n",
    "            book_dict['Число оценок'] = num_scores\n",
    "        num_reviews_tmp = ratings_tmp.find('meta', itemprop=\"reviewCount\")\n",
    "        if num_reviews_tmp:\n",
    "            num_reviews = num_reviews_tmp['content']\n",
    "            book_dict['Число отзывов'] = num_reviews\n",
    "    \n",
    "    avaliable = soup.find('div', class_='rd-page-product__buttons').a['class'][1].find('available') > -1\n",
    "    book_dict['В наличии'] = avaliable\n",
    "    \n",
    "    about_tmp = soup.find('div', class_='rd-page-product__desc-body')\n",
    "    if about_tmp:\n",
    "        about = about_tmp.text\n",
    "        book_dict['Описание'] = about\n",
    "    \n",
    "    characteristics_raw = soup.find('div', class_='rd-page-product__desc-params')\n",
    "    char_names = characteristics_raw.find_all('span', itemprop='name')\n",
    "    char_values = characteristics_raw.find_all(itemprop='value')\n",
    "    book_dict.update(zip([i.text for i in char_names], [i.text for i in char_values]))\n",
    "    \n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book pages to process: 2461\n",
      "50 -> 100 -> 150 -> 200 -> 250 -> 300 -> 350 -> 400 -> 450 -> 500 -> 550 -> 600 -> 650 -> 700 -> 750 -> 800 -> 850 -> 900 -> 950 -> 1000 -> 1050 -> 1100 -> 1150 -> 1200 -> 1250 -> 1300 -> 1350 -> 1400 -> 1450 -> 1500 -> 1550 -> 1600 -> 1650 -> 1700 -> 1750 -> 1800 -> 1850 -> 1900 -> 1950 -> 2000 -> 2050 -> 2100 -> 2150 -> 2200 -> 2250 -> 2300 -> 2350 -> 2400 -> 2450 -> "
     ]
    }
   ],
   "source": [
    "counter = Value('i', 0)\n",
    "print(f'Book pages to process: {len(all_books)}')\n",
    "with Pool(processes=10) as pool:\n",
    "    all_dicts = pool.map(process_page, all_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_dicts)\n",
    "df.sort_values(by=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hw_3.csv', mode='w', encoding='utf-8') as f_csv:\n",
    "    df.to_csv(f_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
